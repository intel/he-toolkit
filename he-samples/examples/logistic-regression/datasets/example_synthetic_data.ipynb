{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Logistic Regression HE Inference\n",
    "\n",
    "This is a sample code to generate datasets for the LR HE inference example. It has been tested on ```python3 >= 3.5```. \n",
    "\n",
    "### Notes\n",
    "1. The range of the all data point must be in ```[-1, 1]``` range, due to the utilization of a 3-degree polynomial representation of the sigmoid function.\n",
    "2. For using own datasets, it must be in ```(name)_eval.csv``` and ```(name)_lrmodel.csv```. More details about the csv templates are described below.\n",
    "3. After running this script, make sure to copy the csv files to ```${HE_SAMPLES}/build/examples/logistic-regression/datasets```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lr_base as lrb\n",
    "import generate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Configuration\n",
    "Dataset name, number of samples, and number of features can be set. It will generate ```n_samples``` of data then split into train, test and eval set with ```2:1:1``` ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = \"lrtest\"\n",
    "n_samples = 10000  # 2500 samples for eval set\n",
    "n_features = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "Generated data is first scaled to ```[-1, 1]``` range, then exclusively split to train, test and eval set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_eval, y_eval = generate_data.generateSynData(\n",
    "    n_samples, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Training\n",
    "We provide a simple logistic regression training script based on [Homomorphic training of 30,000 logistic regression models](https://eprint.iacr.org/2019/425) by Bergamaschi et al.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "== Logistic Regression Training ==\n",
      "Epoch: 0, - loss: 0.7590270072516531 - acc: 0.802\n",
      "Epoch: 1, - loss: 0.7590270072516531 - acc: 0.802\n",
      "Epoch: 2, - loss: 0.7262199385987 - acc: 0.8332\n",
      "Epoch: 3, - loss: 0.6971525441158094 - acc: 0.8544\n",
      "Epoch: 4, - loss: 0.6703830849331164 - acc: 0.8628\n",
      "Epoch: 5, - loss: 0.6454043833825989 - acc: 0.8712\n",
      "Epoch: 6, - loss: 0.6219822062877712 - acc: 0.8728\n",
      "Epoch: 7, - loss: 0.5999795015244065 - acc: 0.8744\n",
      "Epoch: 8, - loss: 0.5792977563454041 - acc: 0.8772\n",
      "Epoch: 9, - loss: 0.5598552240090058 - acc: 0.8784\n",
      "Accuracy: 0.882   f1 score: 0.8893058161350844\n"
     ]
    }
   ],
   "source": [
    "bias, weights = generate_data.doTrain(X_train, y_train, X_test, y_test, verbose=True)\n",
    "biasweights = np.concatenate(([bias], weights), axis=0)\n",
    "\n",
    "# evaluate model\n",
    "_, acc, _, f1 = lrb.test_poly3(X_eval, y_eval, biasweights)\n",
    "print(\"Accuracy:\", acc, \"  f1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to csv\n",
    "Save the eval set and trained logistic regression model to csv files. The first row of the (eval) data file is the feature names. In this code, it will be ```feature_0, feature_1, ... target```, implying that the final column contains the binary target ```0``` or ```1```.\n",
    "\n",
    "For using own weights, it must be stored in a single row csv file with ```bias, w[0], w[1], ... , w[n_features - 1]``` template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data.saveModel(dataname, bias, weights)\n",
    "generate_data.saveData(dataname, X_eval, y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
